#LyX 2.4 created this file. For more info see https://www.lyx.org/
\lyxformat 620
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{placeins}   % para \FloatBarrier
\usepackage{caption}    % para \captionof en tablas no flotantes
\usepackage{float}      % para usar [H] en \begin{table}[H]

% Ajustes suaves de espacios alrededor de flotantes (opcional)
\setlength{\textfloatsep}{10pt plus 1pt minus 2pt}
\setlength{\floatsep}{8pt plus 1pt minus 2pt}
\captionsetup[table]{skip=4pt}
\usepackage{tikz}
\usetikzlibrary{positioning,calc,arrows.meta,fit}
\usepackage{float}      % [H] = Here definitely
\usepackage{placeins}   % \FloatBarrier
\usepackage{graphicx}   % imágenes
\usepackage{caption}    % mejor manejo de títulos
\usepackage{booktabs}   % tablas más limpias (opcional)
\setlength{\textfloatsep}{10pt plus 1pt minus 2pt} % menos espacio vertical
\setlength{\floatsep}{8pt plus 1pt minus 2pt}
\end_preamble
\use_default_options true
\maintain_unincluded_children no
\language english
\language_package default
\inputencoding utf8
\fontencoding auto
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_roman_osf false
\font_sans_osf false
\font_typewriter_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement class
\float_alignment class
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_formatted_ref 0
\use_minted 0
\use_lineno 0
\index Index
\shortcut idx
\color #008080
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tablestyle default
\tracking_changes false
\output_changes false
\change_bars false
\postpone_fragile_content true
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\docbook_table_output 0
\docbook_mathml_prefix 1
\end_header

\begin_body

\begin_layout Section
Preparación de entorno
\end_layout

\begin_layout Standard
El propósito de esta etapa fue construir la base de datos en un formato adecuado para ser procesado por la red neuronal en PyTorch.
 Se buscó garantizar que todas las instancias estuvieran correctamente representadas,
 que las etiquetas fueran consistentes y que el proceso de lectura y transformación de los datos no introdujera inconsistencias.
 Esto incluyó el diseño de un mapeo estable entre etiquetas de clases y valores enteros,
 así como la verificación de la dimensionalidad de los atributos.
\end_layout

\begin_layout Standard
El preprocesamiento reveló varios hallazgos importantes sobre la estructura del dataset KDD99:
\end_layout

\begin_layout Subsection
Cantidad de clases presentes:
 
\end_layout

\begin_layout Standard
Se identificaron 23 clases en total,
 cada una representada en el mapeo label2idx.
 Ejemplos de este mapeo inicial incluyen asociaciones como:
\end_layout

\begin_layout Itemize
back.
 → 0
\end_layout

\begin_layout Itemize
buffer_overflow.
 → 1
\end_layout

\begin_layout Itemize
ftp_write.
 → 2
\end_layout

\begin_layout Itemize
guess_passwd.
 → 3
\end_layout

\begin_layout Itemize
imap.
 → 4
\end_layout

\begin_layout Standard
Este proceso aseguró un etiquetado uniforme y reproducible en todas las particiones (train,
 val,
 test).
\end_layout

\begin_layout Subsection
Filtrado de valores faltantes:
\end_layout

\begin_layout Standard
Durante la construcción del dataset se detectaron filas con etiquetas NaN (sin clase asignada).
 Estos registros fueron eliminados para no introducir ruido en el entrenamiento:
\end_layout

\begin_layout Itemize
103,815 instancias removidas en el conjunto de entrenamiento.
\end_layout

\begin_layout Itemize
62,819 instancias removidas en el conjunto de validación.
\end_layout

\begin_layout Itemize
62,910 instancias removidas en el conjunto de prueba.
\end_layout

\begin_layout Standard
Esta depuración fue crítica,
 pues sin ella los modelos hubieran intentado aprender patrones de instancias incompletas,
 afectando la estabilidad del entrenamiento.
\end_layout

\begin_layout Subsection
Dimensionalidad de las características:
\end_layout

\begin_layout Standard
Tras la limpieza,
 cada registro quedó representado con 118 atributos numéricos.
 Esta dimensionalidad confirma que se preservaron tanto las variables originales como las transformaciones categóricas necesarias (por ejemplo,
 dummies de protocol_type,
 service,
 flag).
\end_layout

\begin_layout Subsection
Distribución de instancias:
\end_layout

\begin_layout Standard
Luego de la limpieza,
 los conjuntos resultaron con la siguiente distribución:
\end_layout

\begin_layout Itemize
Entrenamiento:
 345,814 instancias.
\end_layout

\begin_layout Itemize
Validación:
 74,102 instancias.
\end_layout

\begin_layout Itemize
Prueba:
 74,105 instancias.
\end_layout

\begin_layout Standard
Este balance (~70/15/15) asegura que los resultados experimentales puedan evaluarse de manera justa y generalizable.
\end_layout

\begin_layout Subsection
Verificación con DataLoader:
\end_layout

\begin_layout Standard
Finalmente,
 al generar un batch de entrenamiento se observó la forma:
\end_layout

\begin_layout Itemize
X:
 [512,
 118]
\end_layout

\begin_layout Itemize
Y:
 [512]
\end_layout

\begin_layout Standard
Esto confirma que los datos quedaron correctamente preparados para el flujo de entrenamiento de la red neuronal.
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% (ERT) justo ANTES de la primera tabla:
\end_layout

\begin_layout Plain Layout


\backslash
FloatBarrier
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% (ERT con la tabla)
\end_layout

\begin_layout Plain Layout


\backslash
begin{table}[H]
\end_layout

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
caption{Distribución final de instancias después de la depuración de etiquetas NaN}
\end_layout

\begin_layout Plain Layout


\backslash
label{tab:dataset_splits}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{lrr}
\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
textbf{Conjunto} & 
\backslash
textbf{Instancias eliminadas (NaN)} & 
\backslash
textbf{Instancias finales} 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

Entrenamiento & 103,815 & 345,814 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

Validación    & 62,819  & 74,102  
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

Prueba        & 62,910  & 74,105  
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
textbf{Total} & 229,544 & 494,021 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\begin_layout Plain Layout


\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% (ERT) justo DESPUÉS de la primera tabla:
\end_layout

\begin_layout Plain Layout


\backslash
FloatBarrier
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
FloatBarrier
\end_layout

\begin_layout Plain Layout


\backslash
begin{center}
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand{
\backslash
arraystretch}{1.15}
\end_layout

\begin_layout Plain Layout


\backslash
captionof{table}{Mapeo de clases a índices en el dataset KDD99}
\end_layout

\begin_layout Plain Layout


\backslash
label{tab:label2idx_threeCols}
\end_layout

\begin_layout Plain Layout


\backslash
resizebox{
\backslash
textwidth}{!}{%
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|l|c|l|c|l|c|}
\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
multicolumn{2}{|c|}{
\backslash
textbf{Columna A}} & 
\backslash
multicolumn{2}{c|}{
\backslash
textbf{Columna B}} & 
\backslash
multicolumn{2}{c|}{
\backslash
textbf{Columna C}} 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
textbf{Clase} & 
\backslash
textbf{Índice} & 
\backslash
textbf{Clase} & 
\backslash
textbf{Índice} & 
\backslash
textbf{Clase} & 
\backslash
textbf{Índice} 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout

back.
             & 0  & multihop.
       & 8  & teardrop.
      & 16 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

buffer
\backslash
_overflow.
 & 1  & nmap.
           & 9  & warezclient.
   & 17 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

ftp
\backslash
_write.
       & 2  & phf.
            & 10 & warezmaster.
   & 18 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

guess
\backslash
_passwd.
    & 3  & pod.
            & 22 & normal.
        & 19 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

imap.
             & 4  & portsweep.
      & 12 & neptune.
       & 20 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

ipsweep.
          & 5  & satan.
          & 13 & perl.
          & 21 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

land.
             & 6  & smurf.
          & 14 &                &    
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

loadmodule.
       & 7  & spy.
            & 15 &                &    
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}%
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout


\backslash
end{center}
\end_layout

\begin_layout Plain Layout


\backslash
FloatBarrier
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Arquitectura FCN
\end_layout

\begin_layout Standard
En esta etapa del trabajo se diseñó una red neuronal de tipo Fully Connected Network (FCN) específicamente adaptada para el problema de clasificación multiclase del dataset KDD99.
 La elección de este tipo de arquitectura responde a la necesidad de capturar de forma eficiente relaciones no lineales entre un gran número de atributos numéricos,
 garantizando al mismo tiempo un equilibrio entre capacidad de representación y costo computacional.
\end_layout

\begin_layout Standard
La red se estructuró con un total de cuatro capas densamente conectadas,
 en donde cada neurona de una capa se enlaza con todas las neuronas de la siguiente.
 Esta característica permite que el modelo aprenda patrones complejos en los datos,
 más allá de simples combinaciones lineales.
 El diseño final de la arquitectura quedó conformado de la siguiente manera:
\end_layout

\begin_layout Itemize
La primera capa oculta incluyó 256 neuronas con activación ReLU,
 acompañada de un mecanismo de normalización por lotes (Batch Normalization),
 lo que estabiliza el entrenamiento y acelera la convergencia.
\end_layout

\begin_layout Itemize
La segunda capa oculta contó con 128 neuronas,
 también con activación ReLU y normalización por lotes,
 manteniendo la coherencia del flujo de datos entre las capas.
\end_layout

\begin_layout Itemize
La tercera capa oculta estuvo compuesta por 64 neuronas,
 replicando la misma configuración de activación y normalización,
 pero reduciendo gradualmente la dimensionalidad de la representación interna.
\end_layout

\begin_layout Standard
Finalmente,
 la capa de salida se conformó por 23 neuronas,
 correspondientes al número total de clases del dataset KDD99.
 Esta capa utilizó una activación softmax,
 generando una distribución de probabilidades sobre las posibles categorías de salida.
\end_layout

\begin_layout Standard
Además de las capas descritas,
 se implementó un mecanismo de regularización mediante dropout con una tasa del 20%.
 Este componente se aplicó en las capas ocultas,
 con el fin de mitigar el sobreajuste (overfitting) y favorecer la capacidad de generalización del modelo frente a datos no vistos.
 La combinación de dropout y batch normalization permitió obtener un balance adecuado entre robustez y eficiencia durante el proceso de entrenamiento.
\end_layout

\begin_layout Standard
El uso sistemático de la función de activación ReLU resultó esencial para introducir no linealidad en la red y evitar la saturación de gradientes que ocurre con funciones tradicionales como la sigmoide o la tangente hiperbólica.
 A su vez,
 la normalización por lotes colaboró en mantener estables los gradientes,
 permitiendo que el aprendizaje fuese más rápido y confiable.
\end_layout

\begin_layout Standard
En conjunto,
 la arquitectura propuesta logró mantener un número de parámetros manejable en relación con la capacidad de cómputo disponible,
 lo que representa un aspecto crucial en problemas con datasets extensos y desbalanceados como el presente.
 Así,
 se aseguró que la red fuese lo suficientemente profunda como para capturar la complejidad del problema,
 pero sin incurrir en un modelo excesivamente pesado o difícil de entrenar.
\end_layout

\begin_layout Standard
Finalmente,
 se realizó una verificación del modelo a través de un forward pass inicial con un batch de datos provenientes del DataLoader.
 Esta prueba confirmó que la red producía una salida en el formato esperado:
 un vector de 23 probabilidades para cada una de las instancias evaluadas,
 lo cual validó la correcta implementación de la arquitectura y su preparación para la siguiente etapa de entrenamiento.
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
FloatBarrier
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}[H]
\end_layout

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
caption{Resumen de la arquitectura de la red neuronal FCN utilizada}
\end_layout

\begin_layout Plain Layout


\backslash
label{tab:fcn_architecture}
\end_layout

\begin_layout Plain Layout


\backslash
begin{tabular}{|c|c|c|c|}
\end_layout

\begin_layout Plain Layout


\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
textbf{Capa} & 
\backslash
textbf{Número de neuronas} & 
\backslash
textbf{Función de activación} & 
\backslash
textbf{Otras operaciones} 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Entrada & 118 & -- & Atributos normalizados del dataset 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Oculta 1 & 256 & ReLU & Batch Normalization + Dropout (20
\backslash
%) 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Oculta 2 & 128 & ReLU & Batch Normalization + Dropout (20
\backslash
%) 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Oculta 3 & 64  & ReLU & Batch Normalization + Dropout (20
\backslash
%) 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout

Salida   & 23  & Softmax & Probabilidades de pertenencia a cada clase 
\backslash

\backslash
 
\backslash
hline
\end_layout

\begin_layout Plain Layout


\backslash
end{tabular}
\end_layout

\begin_layout Plain Layout


\backslash
end{table}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
FloatBarrier
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{figure}[H]
\end_layout

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
includegraphics[width=0.9
\backslash
textwidth]{fcn_diagram.png}
\end_layout

\begin_layout Plain Layout


\backslash
caption{Diagrama esquemático de la red FCN utilizada (256–128–64–23).}
\end_layout

\begin_layout Plain Layout


\backslash
label{fig:fcn_diagram}
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
FloatBarrier
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{figure}[H]
\end_layout

\begin_layout Plain Layout


\backslash
centering
\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[
\end_layout

\begin_layout Plain Layout

    layer/.style={draw,
 rounded corners=2pt,
 minimum width=3.5cm,
 minimum height=1.0cm,
 very thick,
 fill=gray!8},
\end_layout

\begin_layout Plain Layout

    inout/.style={draw,
 rounded corners=2pt,
 minimum width=3.5cm,
 minimum height=1.0cm,
 very thick,
 fill=gray!18},
\end_layout

\begin_layout Plain Layout

    ann/.style={font=
\backslash
small},
\end_layout

\begin_layout Plain Layout

    ->,
 >=Latex,
 line width=0.9pt
\end_layout

\begin_layout Plain Layout

]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

% Nodos (capas)
\end_layout

\begin_layout Plain Layout


\backslash
node[inout] (input)  { 
\backslash
textbf{Entrada} 
\backslash

\backslash
 
\backslash
footnotesize 118 atributos};
\end_layout

\begin_layout Plain Layout


\backslash
node[layer,
 right=1.9cm of input]  (h1) { 
\backslash
textbf{Oculta 1} 
\backslash

\backslash
 
\backslash
footnotesize 256 neuronas 
\backslash

\backslash
 
\backslash
footnotesize ReLU + BatchNorm + Dropout 20
\backslash
%};
\end_layout

\begin_layout Plain Layout


\backslash
node[layer,
 right=1.9cm of h1]     (h2) { 
\backslash
textbf{Oculta 2} 
\backslash

\backslash
 
\backslash
footnotesize 128 neuronas 
\backslash

\backslash
 
\backslash
footnotesize ReLU + BatchNorm + Dropout 20
\backslash
%};
\end_layout

\begin_layout Plain Layout


\backslash
node[layer,
 right=1.9cm of h2]     (h3) { 
\backslash
textbf{Oculta 3} 
\backslash

\backslash
 
\backslash
footnotesize 64 neuronas 
\backslash

\backslash
 
\backslash
footnotesize ReLU + BatchNorm + Dropout 20
\backslash
%};
\end_layout

\begin_layout Plain Layout


\backslash
node[inout,
 right=1.9cm of h3]     (out) { 
\backslash
textbf{Salida} 
\backslash

\backslash
 
\backslash
footnotesize 23 clases (softmax)};
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

% Flechas
\end_layout

\begin_layout Plain Layout


\backslash
draw (input) -- (h1);
\end_layout

\begin_layout Plain Layout


\backslash
draw (h1) -- (h2);
\end_layout

\begin_layout Plain Layout


\backslash
draw (h2) -- (h3);
\end_layout

\begin_layout Plain Layout


\backslash
draw (h3) -- (out);
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

% Comentario inferior (opcional)
\end_layout

\begin_layout Plain Layout


\backslash
node[ann,
 below=0.8cm of h2,
 align=center] (note) 
\end_layout

\begin_layout Plain Layout

    { 
\backslash
footnotesize Arquitectura FCN densamente conectada:
 118 $
\backslash
rightarrow$ 256 $
\backslash
rightarrow$ 128 $
\backslash
rightarrow$ 64 $
\backslash
rightarrow$ 23.
 
\backslash

\backslash
[-2pt]
\end_layout

\begin_layout Plain Layout

      
\backslash
footnotesize Las capas ocultas emplean ReLU,
 Batch Normalization y Dropout (20
\backslash
%).};
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\begin_layout Plain Layout


\backslash
caption{Diagrama esquemático de la red FCN utilizada (256–128–64–23).}
\end_layout

\begin_layout Plain Layout


\backslash
label{fig:fcn_architecture}
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_body
\end_document
